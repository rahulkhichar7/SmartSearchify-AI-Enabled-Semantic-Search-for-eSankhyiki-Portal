{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182261c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from time import time\n",
    "import numpy as np\n",
    "import psutil\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de249ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Evaluating model: bert-base-uncased\n",
      "üì¶ Model Size: 417.64 MB\n",
      "‚ö° Inference Time (on corpus): 1.2504 s\n",
      "üìà Test Results:\n",
      "\n",
      "Query: inflation in India based on CPI\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.8324000239372253\n",
      "\n",
      "Query: rural and urban consumer price index\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.7429999709129333\n",
      "\n",
      "Query: general price index for states\n",
      "Top Match: year on year inflation rates % of major states\n",
      "Similarity: 0.7874000072479248\n",
      "\n",
      "Query: inflation rates for all India\n",
      "Top Match: all india year on year inflation rates % for g\n",
      "Similarity: 0.842199981212616\n",
      "\n",
      "Query: state-wise inflation trend\n",
      "Top Match: year on year inflation rates % of major states\n",
      "Similarity: 0.7551000118255615\n",
      "\n",
      "üîç Evaluating model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Model Size: 475.49 MB\n",
      "‚ö° Inference Time (on corpus): 1.2978 s\n",
      "üìà Test Results:\n",
      "\n",
      "Query: inflation in India based on CPI\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.9854000210762024\n",
      "\n",
      "Query: rural and urban consumer price index\n",
      "Top Match: year on year inflation rates % of major states\n",
      "Similarity: 0.9745000004768372\n",
      "\n",
      "Query: general price index for states\n",
      "Top Match: year on year inflation rates % of major states\n",
      "Similarity: 0.9761000275611877\n",
      "\n",
      "Query: inflation rates for all India\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.984000027179718\n",
      "\n",
      "Query: state-wise inflation trend\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.9747999906539917\n",
      "\n",
      "üîç Evaluating model: sentence-transformers/all-MiniLM-L6-v2\n",
      "üì¶ Model Size: N/A (pre-compiled) MB\n",
      "‚ö° Inference Time (on corpus): 0.3056 s\n",
      "üìà Test Results:\n",
      "\n",
      "Query: inflation in India based on CPI\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.8023999929428101\n",
      "\n",
      "Query: rural and urban consumer price index\n",
      "Top Match: general cpi for states for rural urban and com\n",
      "Similarity: 0.6980999708175659\n",
      "\n",
      "Query: general price index for states\n",
      "Top Match: general cpi for states for rural urban and com\n",
      "Similarity: 0.5823000073432922\n",
      "\n",
      "Query: inflation rates for all India\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.8252999782562256\n",
      "\n",
      "Query: state-wise inflation trend\n",
      "Top Match: year on year inflation rates % of major states\n",
      "Similarity: 0.713699996471405\n",
      "\n",
      "üîç Evaluating model: sentence-transformers/paraphrase-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive - iitgn.ac.in\\Desktop\\Projects\\SmartSearchify-AI-Enabled-Semantic-Search-for-eSankhyiki-Portal\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Model Size: N/A (pre-compiled) MB\n",
      "‚ö° Inference Time (on corpus): 0.0452 s\n",
      "üìà Test Results:\n",
      "\n",
      "Query: inflation in India based on CPI\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.8091999888420105\n",
      "\n",
      "Query: rural and urban consumer price index\n",
      "Top Match: general cpi for states for rural urban and com\n",
      "Similarity: 0.6218000054359436\n",
      "\n",
      "Query: general price index for states\n",
      "Top Match: year on year inflation rates % of major states\n",
      "Similarity: 0.5242999792098999\n",
      "\n",
      "Query: inflation rates for all India\n",
      "Top Match: all india year on year inflation rates % for g\n",
      "Similarity: 0.847599983215332\n",
      "\n",
      "Query: state-wise inflation trend\n",
      "Top Match: year on year inflation rates % of major states\n",
      "Similarity: 0.7756999731063843\n",
      "\n",
      "üîç Evaluating model: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive - iitgn.ac.in\\Desktop\\Projects\\SmartSearchify-AI-Enabled-Semantic-Search-for-eSankhyiki-Portal\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Model Size: N/A (pre-compiled) MB\n",
      "‚ö° Inference Time (on corpus): 0.2689 s\n",
      "üìà Test Results:\n",
      "\n",
      "Query: inflation in India based on CPI\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.7483000159263611\n",
      "\n",
      "Query: rural and urban consumer price index\n",
      "Top Match: general cpi for states for rural urban and com\n",
      "Similarity: 0.807699978351593\n",
      "\n",
      "Query: general price index for states\n",
      "Top Match: general cpi for states for rural urban and com\n",
      "Similarity: 0.7250000238418579\n",
      "\n",
      "Query: inflation rates for all India\n",
      "Top Match: all india year on year inflation rates % for g\n",
      "Similarity: 0.8540999889373779\n",
      "\n",
      "Query: state-wise inflation trend\n",
      "Top Match: year on year inflation rates % of major states\n",
      "Similarity: 0.7803999781608582\n",
      "\n",
      "üîç Evaluating model: sentence-transformers/multi-qa-MiniLM-L6-cos-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive - iitgn.ac.in\\Desktop\\Projects\\SmartSearchify-AI-Enabled-Semantic-Search-for-eSankhyiki-Portal\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\models--sentence-transformers--multi-qa-MiniLM-L6-cos-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Model Size: N/A (pre-compiled) MB\n",
      "‚ö° Inference Time (on corpus): 0.0416 s\n",
      "üìà Test Results:\n",
      "\n",
      "Query: inflation in India based on CPI\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.8515999913215637\n",
      "\n",
      "Query: rural and urban consumer price index\n",
      "Top Match: general cpi for states for rural urban and com\n",
      "Similarity: 0.6211000084877014\n",
      "\n",
      "Query: general price index for states\n",
      "Top Match: general cpi for states for rural urban and com\n",
      "Similarity: 0.5223000049591064\n",
      "\n",
      "Query: inflation rates for all India\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.8173999786376953\n",
      "\n",
      "Query: state-wise inflation trend\n",
      "Top Match: year on year inflation rates % of major states\n",
      "Similarity: 0.7167999744415283\n",
      "\n",
      "üîç Evaluating model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive - iitgn.ac.in\\Desktop\\Projects\\SmartSearchify-AI-Enabled-Semantic-Search-for-eSankhyiki-Portal\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Model Size: N/A (pre-compiled) MB\n",
      "‚ö° Inference Time (on corpus): 0.0855 s\n",
      "üìà Test Results:\n",
      "\n",
      "Query: inflation in India based on CPI\n",
      "Top Match: all india inflation rate based on cpi base 201\n",
      "Similarity: 0.8590999841690063\n",
      "\n",
      "Query: rural and urban consumer price index\n",
      "Top Match: general cpi for states for rural urban and com\n",
      "Similarity: 0.48080000281333923\n",
      "\n",
      "Query: general price index for states\n",
      "Top Match: year on year inflation rates % of major states\n",
      "Similarity: 0.6478999853134155\n",
      "\n",
      "Query: inflation rates for all India\n",
      "Top Match: all india year on year inflation rates % for g\n",
      "Similarity: 0.8781999945640564\n",
      "\n",
      "Query: state-wise inflation trend\n",
      "Top Match: year on year inflation rates % of major states\n",
      "Similarity: 0.8495000004768372\n"
     ]
    }
   ],
   "source": [
    "search_texts = [\n",
    "    \"all india year on year inflation rates % for g\",\n",
    "    \"all india inflation rate based on cpi base 201\",\n",
    "    \"year on year inflation rates % of major states\",\n",
    "    \"general cpi for states for rural urban and com\",\n",
    "    \"all india general group and sub group level cp\"\n",
    "]\n",
    "\n",
    "test_queries = [\n",
    "    \"inflation in India based on CPI\",\n",
    "    \"rural and urban consumer price index\",\n",
    "    \"general price index for states\",\n",
    "    \"inflation rates for all India\",\n",
    "    \"state-wise inflation trend\"\n",
    "]\n",
    "\n",
    "class SemanticSearchModel(nn.Module):\n",
    "    def __init__(self, model_name='bert-base-uncased'):\n",
    "        super(SemanticSearchModel, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.sentence_bert = False\n",
    "\n",
    "        if model_name == 'bert-base-uncased':\n",
    "            self.model = BertModel.from_pretrained(model_name)\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        elif model_name == 'roberta-base':\n",
    "            self.model = RobertaModel.from_pretrained(model_name)\n",
    "            self.tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "        elif model_name.startswith(\"sentence-transformers\"):\n",
    "            self.model = SentenceTransformer(model_name)\n",
    "            self.tokenizer = None\n",
    "            self.sentence_bert = True\n",
    "\n",
    "    def get_embeddings(self, texts):\n",
    "        if self.sentence_bert:\n",
    "            return self.model.encode(texts, convert_to_tensor=True)\n",
    "        else:\n",
    "            tokens = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**tokens)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling\n",
    "            return embeddings\n",
    "\n",
    "# Get model size\n",
    "def get_model_size(model):\n",
    "    if isinstance(model, SentenceTransformer):\n",
    "        return \"N/A (pre-compiled)\"\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    return round(params * 4 / (1024 ** 2), 2)  # in MB\n",
    "\n",
    "# Inference time\n",
    "def measure_inference_time(model, texts):\n",
    "    start = time()\n",
    "    model.get_embeddings(texts)\n",
    "    return round(time() - start, 4)\n",
    "\n",
    "# Compare \n",
    "def get_best_matches(model, query, corpus_embeddings, corpus_texts, top_k=1):\n",
    "    query_embedding = model.get_embeddings([query])\n",
    "    scores = cosine_similarity(query_embedding.cpu(), corpus_embeddings.cpu())[0]\n",
    "    top_idx = np.argsort(scores)[::-1][:top_k]\n",
    "    return [(corpus_texts[i], scores[i]) for i in top_idx]\n",
    "\n",
    "# Models to evaluate\n",
    "model_names = [\n",
    "    'bert-base-uncased',\n",
    "    'roberta-base',\n",
    "    'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    'sentence-transformers/paraphrase-MiniLM-L6-v2',\n",
    "    'sentence-transformers/all-mpnet-base-v2',\n",
    "    'sentence-transformers/multi-qa-MiniLM-L6-cos-v1',\n",
    "    'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "]\n",
    "\n",
    "# Run benchmark\n",
    "for model_name in model_names:\n",
    "    print(f\"\\nüîç Evaluating model: {model_name}\")\n",
    "    model = SemanticSearchModel(model_name)\n",
    "\n",
    "    model_size = get_model_size(model.model)\n",
    "    inference_time = measure_inference_time(model, search_texts)\n",
    "    corpus_embeddings = model.get_embeddings(search_texts)\n",
    "\n",
    "    print(f\"üì¶ Model Size: {model_size} MB\")\n",
    "    print(f\"‚ö° Inference Time (on corpus): {inference_time} s\")\n",
    "    print(\"üìà Test Results:\")\n",
    "\n",
    "    for query in test_queries:\n",
    "        match_text, score = get_best_matches(model, query, corpus_embeddings, search_texts)[0]\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(f\"Top Match: {match_text}\")\n",
    "        print(f\"Similarity: {round(score, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb65683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
